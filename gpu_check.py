import torch
import sys
import subprocess
import platform

def check_gpu_status():
    """GPU ìƒíƒœë¥¼ ìì„¸íˆ í™•ì¸í•˜ëŠ” í•¨ìˆ˜"""
    print("ğŸ” GPU ìƒíƒœ í™•ì¸ ì¤‘...\n")
    
    # 1. PyTorch ë²„ì „ í™•ì¸
    print(f"ğŸ“¦ PyTorch ë²„ì „: {torch.__version__}")
    
    # 2. CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
    cuda_available = torch.cuda.is_available()
    print(f"âš¡ CUDA ì‚¬ìš© ê°€ëŠ¥: {'âœ… ì˜ˆ' if cuda_available else 'âŒ ì•„ë‹ˆì˜¤'}")
    
    if cuda_available:
        # 3. CUDA ë²„ì „
        cuda_version = torch.version.cuda
        print(f"ğŸ”§ CUDA ë²„ì „: {cuda_version}")
        
        # 4. GPU ê°œìˆ˜
        gpu_count = torch.cuda.device_count()
        print(f"ğŸ® GPU ê°œìˆ˜: {gpu_count}")
        
        # 5. ê° GPU ì •ë³´
        for i in range(gpu_count):
            gpu_name = torch.cuda.get_device_name(i)
            gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3  # GB
            print(f"   GPU {i}: {gpu_name} ({gpu_memory:.1f}GB)")
        
        # 6. í˜„ì¬ GPU
        current_device = torch.cuda.current_device()
        print(f"ğŸ¯ í˜„ì¬ GPU: {current_device}")
        
        # 7. GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        allocated = torch.cuda.memory_allocated() / 1024**3
        cached = torch.cuda.memory_reserved() / 1024**3
        print(f"ğŸ’¾ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {allocated:.2f}GB (í• ë‹¹ë¨) / {cached:.2f}GB (ìºì‹œë¨)")
        
    else:
        print("\nâŒ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ì´ìœ :")
        
        # PyTorchê°€ CPU ë²„ì „ì¸ì§€ í™•ì¸
        if not hasattr(torch, 'cuda'):
            print("   â€¢ PyTorchê°€ CPU ì „ìš© ë²„ì „ìœ¼ë¡œ ì„¤ì¹˜ë¨")
        else:
            print("   â€¢ CUDA ë“œë¼ì´ë²„ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
            print("   â€¢ NVIDIA GPUê°€ ì—†ìŒ")
            print("   â€¢ CUDA ë²„ì „ì´ í˜¸í™˜ë˜ì§€ ì•ŠìŒ")
    
    # 8. ì‹œìŠ¤í…œ ì •ë³´
    print(f"\nğŸ’» ì‹œìŠ¤í…œ ì •ë³´:")
    print(f"   OS: {platform.system()} {platform.release()}")
    print(f"   Python: {sys.version}")
    
    return cuda_available

def check_nvidia_driver():
    """NVIDIA ë“œë¼ì´ë²„ ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸"""
    print("\nğŸ”§ NVIDIA ë“œë¼ì´ë²„ í™•ì¸ ì¤‘...")
    
    try:
        # nvidia-smi ëª…ë ¹ì–´ ì‹¤í–‰
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            print("âœ… NVIDIA ë“œë¼ì´ë²„ê°€ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            print("ğŸ“‹ GPU ì •ë³´:")
            lines = result.stdout.split('\n')
            for line in lines[:10]:  # ì²˜ìŒ 10ì¤„ë§Œ ì¶œë ¥
                if line.strip():
                    print(f"   {line}")
            return True
        else:
            print("âŒ NVIDIA ë“œë¼ì´ë²„ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
    except FileNotFoundError:
        print("âŒ nvidia-smi ëª…ë ¹ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    except subprocess.TimeoutExpired:
        print("âŒ nvidia-smi ëª…ë ¹ì–´ ì‹¤í–‰ ì‹œê°„ ì´ˆê³¼.")
        return False

def install_gpu_pytorch():
    """GPUìš© PyTorch ì„¤ì¹˜ ë°©ë²• ì•ˆë‚´"""
    print("\nğŸš€ GPUìš© PyTorch ì„¤ì¹˜ ë°©ë²•:")
    print("1. í˜„ì¬ PyTorch ì œê±°:")
    print("   pip uninstall torch torchaudio")
    print("\n2. GPUìš© PyTorch ì„¤ì¹˜ (CUDA 11.8 ê¸°ì¤€):")
    print("   pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118")
    print("\n3. ë˜ëŠ” CUDA 12.1ìš©:")
    print("   pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu121")
    print("\n4. ì„¤ì¹˜ í›„ í™•ì¸:")
    print("   python -c \"import torch; print(torch.cuda.is_available())\"")

def main():
    print("ğŸ¤ Whisper GPU ìƒíƒœ í™•ì¸ ë„êµ¬")
    print("=" * 50)
    
    # GPU ìƒíƒœ í™•ì¸
    cuda_available = check_gpu_status()
    
    # NVIDIA ë“œë¼ì´ë²„ í™•ì¸
    nvidia_available = check_nvidia_driver()
    
    print("\n" + "=" * 50)
    print("ğŸ“Š ì¢…í•© ê²°ê³¼:")
    
    if cuda_available and nvidia_available:
        print("âœ… GPU ì‚¬ìš© ê°€ëŠ¥! Whisperê°€ GPUì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
        print("ğŸ’¡ ê¶Œì¥ì‚¬í•­: base ëª¨ë¸ + ìµœì í™” ì˜µì…˜ìœ¼ë¡œ ë¹ ë¥¸ ë³€í™˜ì„ ê²½í—˜í•˜ì„¸ìš”!")
    elif nvidia_available and not cuda_available:
        print("âš ï¸  NVIDIA GPUëŠ” ìˆì§€ë§Œ PyTorchê°€ CPU ë²„ì „ì…ë‹ˆë‹¤.")
        print("ğŸ’¡ í•´ê²°ë°©ë²•: GPUìš© PyTorchë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”.")
        install_gpu_pytorch()
    else:
        print("âŒ GPU ì‚¬ìš©ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
        print("ğŸ’¡ CPUì—ì„œë„ Whisperê°€ ë™ì‘í•˜ì§€ë§Œ ì†ë„ê°€ ëŠë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ GPU ì‚¬ìš©ì„ ì›í•œë‹¤ë©´ NVIDIA GPUì™€ ë“œë¼ì´ë²„ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main() 